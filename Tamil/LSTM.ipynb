{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72051a3-705f-47fa-a3ea-a659ff6b0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72ddc7e-5acf-4993-8243-779821a49297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('/Users/arunaa/Python/Sracasam/sarcasm_tam_train.csv')\n",
    "test_df = pd.read_csv('/Users/arunaa/Python/Sracasam/sarcasm_tam_test_without_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e5c055-26ce-4f39-bc39-d3d3aa17757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X_train = train_df['Text']\n",
    "y_train = train_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa188f6-5623-4530-9e30-4884a89fd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5105ca-de12-489f-9c75-4050f187521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e3c3f9f-d38b-4fdd-896c-08ff40901af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for evaluation\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_padded, y_train_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "755dcbb7-0207-4cfb-8b14-2b5023492ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "model.add(LSTM(units=128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e961683-0a9c-4678-ae8b-64aa4ec9b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a876855c-2302-4716-b342-e57e1fcf88b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m740/740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 77ms/step - accuracy: 0.7580 - loss: 0.5094 - val_accuracy: 0.7890 - val_loss: 0.4458\n",
      "Epoch 2/10\n",
      "\u001b[1m740/740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 74ms/step - accuracy: 0.8289 - loss: 0.3764 - val_accuracy: 0.7917 - val_loss: 0.4494\n",
      "Epoch 3/10\n",
      "\u001b[1m740/740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 74ms/step - accuracy: 0.8499 - loss: 0.3327 - val_accuracy: 0.7869 - val_loss: 0.4718\n",
      "Epoch 4/10\n",
      "\u001b[1m740/740\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 74ms/step - accuracy: 0.8725 - loss: 0.2829 - val_accuracy: 0.7837 - val_loss: 0.5271\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train_split, y_train_split, epochs=10, batch_size=32, validation_data=(X_val_split, y_val_split), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c8d0ff-a36e-4e69-bf83-19b6aba917af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the test data\n",
    "X_test = test_df['Text']\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc966e82-8780-4a8e-b595-003291716116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m199/199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "test_predictions_prob = model.predict(X_test_padded)\n",
    "test_predictions = (test_predictions_prob > 0.5).astype(int)\n",
    "test_predictions_labels = label_encoder.inverse_transform(test_predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7be6ccae-87ab-40e0-9422-bd975d4f01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV file\n",
    "test_df['Predicted_Labels'] = test_predictions_labels\n",
    "output_path = '/Users/arunaa/Python/Sracasam/predictions_LSTM.csv'\n",
    "test_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50088934-0908-4001-9090-d6332da5c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "val_predictions_prob = model.predict(X_val_split)\n",
    "val_predictions = (val_predictions_prob > 0.5).astype(int)\n",
    "val_predictions_labels = label_encoder.inverse_transform(val_predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "475dac96-f4c7-466e-8503-73302a898c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_val_split, val_predictions)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_val_split, val_predictions, average='weighted')\n",
    "classification_rep = classification_report(y_val_split, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5fc97c3-78f7-486e-a43a-6253a9da20e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7889753128170442\n",
      "F1 Score: 0.7745064058536517\n",
      "Precision: 0.7753113710410229\n",
      "Recall: 0.7889753128170442\n",
      "Support: None\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86      4318\n",
      "           1       0.66      0.45      0.53      1596\n",
      "\n",
      "    accuracy                           0.79      5914\n",
      "   macro avg       0.74      0.68      0.70      5914\n",
      "weighted avg       0.78      0.79      0.77      5914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation metrics and classification report\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Support: {support}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a42d290-b87e-4b7d-8235-d5ab0270449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text Predicted_Labels\n",
      "0         Kangana wow  awesome yr ye lakdi sbae alh hai    Non-sarcastic\n",
      "1     விழுப்புரம்  வன்னிய கவுண்டர் சார்பாக வாழ்த்துக...    Non-sarcastic\n",
      "2     திரௌபதி திரைப்படம் வெற்றி பெற வாணியர் சமுதாயம்...    Non-sarcastic\n",
      "3     இந்த திரைப்படம் வெற்றிபெற, ஆதி தமிழன் அதாவது இ...    Non-sarcastic\n",
      "4     dai thala pera sonnalay summa tamil naday athi...    Non-sarcastic\n",
      "...                                                 ...              ...\n",
      "6333                      NTR _ Ajith mutuals like here    Non-sarcastic\n",
      "6334  aiyo #thala marana mass #thala love you so muc...    Non-sarcastic\n",
      "6335                      Yan kadavula I love you thala    Non-sarcastic\n",
      "6336  Thank you vijay sethupathi....for acted at syr...    Non-sarcastic\n",
      "6337    Amitab and taapsi manu ki copy picture bnai h y    Non-sarcastic\n",
      "\n",
      "[6338 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the dataset with text and predicted labels\n",
    "print(test_df[['Text', 'Predicted_Labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b06db-eb2d-4d6c-8c9a-30fb76794fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d62c4e-1e69-4c6d-915f-d90fe736a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM, Bidirectional, TimeDistributed, Dropout, Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f536c5-77a1-438d-879d-3d59772fc356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('/Users/arunaa/Python/Sracasam/Malayalam/sarcasm_mal_train.csv')\n",
    "test_df = pd.read_csv('/Users/arunaa/Python/Sracasam/Malayalam/sarcasm_mal_test_without_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b636a2-18e2-464d-9bb5-55d778a403e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X_train = train_df['Text']\n",
    "y_train = train_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff7236e3-7163-401c-9d33-f7670947f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faa7a0f-9efe-479b-bec9-5476d5305d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101ab414-b423-4bc7-8765-7c99f6c375fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for evaluation\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_padded, y_train_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6510bb-89c8-4810-ab32-682b83dfa5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Attention layer\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='att_weight', shape=(input_shape[-1], input_shape[-1]), initializer='uniform', trainable=True)\n",
    "        self.b = self.add_weight(name='att_bias', shape=(input_shape[-1],), initializer='uniform', trainable=True)\n",
    "        self.u = self.add_weight(name='att_var', shape=(input_shape[-1],), initializer='uniform', trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        u_it = K.tanh(K.bias_add(K.dot(x, self.W), self.b))\n",
    "        ait = K.exp(K.sum(K.dot(u_it, K.expand_dims(self.u, -1)), axis=-1))\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = x * ait\n",
    "        return K.sum(weighted_input, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08d8a9e2-d668-4240-948b-1ae1ccf26b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build the HAN model\n",
    "input_layer = Input(shape=(100,))\n",
    "embedding_layer = Embedding(input_dim=5000, output_dim=128, input_length=100)(input_layer)\n",
    "lstm_layer = Bidirectional(LSTM(units=128, return_sequences=True))(embedding_layer)\n",
    "attention_layer = AttentionLayer()(lstm_layer)\n",
    "dropout_layer = Dropout(0.5)(attention_layer)\n",
    "output_layer = Dense(units=1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d39360-2a4d-4259-b86c-2e6cdbe3159a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 94ms/step - accuracy: 0.8165 - loss: 0.4643 - val_accuracy: 0.8480 - val_loss: 0.3713\n",
      "Epoch 2/10\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 108ms/step - accuracy: 0.8859 - loss: 0.2912 - val_accuracy: 0.8525 - val_loss: 0.3809\n",
      "Epoch 3/10\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 110ms/step - accuracy: 0.9144 - loss: 0.2241 - val_accuracy: 0.8385 - val_loss: 0.4466\n",
      "Epoch 4/10\n",
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 111ms/step - accuracy: 0.9479 - loss: 0.1582 - val_accuracy: 0.8196 - val_loss: 0.4971\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "history = model.fit(X_train_split, y_train_split, epochs=10, batch_size=32, validation_data=(X_val_split, y_val_split), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f39f0751-e3cb-479b-b97c-6fdb15abac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the test data\n",
    "X_test = test_df['Text']\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618ca409-953c-4725-895a-f6ad77765c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "test_predictions_prob = model.predict(X_test_padded)\n",
    "test_predictions = (test_predictions_prob > 0.5).astype(int)\n",
    "test_predictions_labels = label_encoder.inverse_transform(test_predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856aefe7-9ea1-4742-a976-0dd660cbccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV file\n",
    "test_df['Predicted_Labels'] = test_predictions_labels\n",
    "output_path = '/Users/arunaa/Python/Sracasam/Malayalam/predictions_HAN_mal.csv'\n",
    "test_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138ae49b-06a3-4df6-9f7e-9ba12a491838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "val_predictions_prob = model.predict(X_val_split)\n",
    "val_predictions = (val_predictions_prob > 0.5).astype(int)\n",
    "val_predictions_labels = label_encoder.inverse_transform(val_predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b56977d-2eb0-45cc-bcd6-9c3e31952bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_val_split, val_predictions)\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_val_split, val_predictions, average='weighted')\n",
    "classification_rep = classification_report(y_val_split, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e04fc39-5a3b-45c7-9807-2ab1cb7ffbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8479909021986354\n",
      "F1 Score: 0.8259634530104297\n",
      "Precision: 0.8319381929950196\n",
      "Recall: 0.8479909021986354\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      2142\n",
      "           1       0.70      0.34      0.46       496\n",
      "\n",
      "    accuracy                           0.85      2638\n",
      "   macro avg       0.78      0.65      0.68      2638\n",
      "weighted avg       0.83      0.85      0.83      2638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation metrics and classification report\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e72d273c-224d-4174-8097-ed4a661da19d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text Predicted_Labels\n",
      "0     Shavakallarayile Kuzhimaadathile Peril Oru Let...    Non-sarcastic\n",
      "1     ഗീതു മോഹൻദാസ് മലയാള സിനിമക്കു നൽകുന്ന വമ്പൻ ഗി...    Non-sarcastic\n",
      "2                      Ente ponno ah sound🥰🥰 poli poli🤘    Non-sarcastic\n",
      "3     Villain sharafudheen  ennu thonnunnavar likikk...    Non-sarcastic\n",
      "4                    pulimurukan trailer ano kanunath 🤔    Non-sarcastic\n",
      "...                                                 ...              ...\n",
      "2821  Ente ponno oru adaaru jagapoka aanenu manasila...    Non-sarcastic\n",
      "2822  എന്റെ ഇക്ക nja നമിച്ചു... ഒരു രക്ഷയില്ല ഹെവി ഐ...    Non-sarcastic\n",
      "2823  ദേ ഇപ്പൊ കണ്ട് ഇറങ്ങിയതേ ഉള്ളു  96  Karikku (+...    Non-sarcastic\n",
      "2824  1) Drisyam 2) Memories  3) Seconds 4) Grand ma...    Non-sarcastic\n",
      "2825  Super mammoookkkaaa... ....   Oru lalettan bha...    Non-sarcastic\n",
      "\n",
      "[2826 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the dataset with text and predicted labels\n",
    "print(test_df[['Text', 'Predicted_Labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec79558-19d3-45b2-a402-27d29a897311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
